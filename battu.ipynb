{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow_hub as hub\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.optimizers import SGD  \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hp\\Downloads\\lm\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hp\\Downloads\\lm\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "birds_csv = 'small_birds_dataset\\metadata.csv'\n",
    "base_data_path = 'small_birds_dataset'\n",
    "pd_data = pd.read_csv(birds_csv)\n",
    "\n",
    "# Define classes \n",
    "my_classes = ['White-breasted Wood-Wren', 'House Sparrow', 'Red Crossbill', 'Chestnut-crowned Antpitta', 'Azara\\'s Spinetail']\n",
    "map_class_to_id = {bird_class: idx for idx, bird_class in enumerate(my_classes)}\n",
    "\n",
    "\n",
    "filtered_pd = pd_data[pd_data['common_name'].isin(my_classes)]\n",
    "\n",
    "\n",
    "class_id = filtered_pd['common_name'].apply(lambda name: map_class_to_id[name])\n",
    "filtered_pd = filtered_pd.assign(target=class_id)\n",
    "\n",
    "\n",
    "full_path = filtered_pd.apply(lambda row: os.path.join(base_data_path, row['split'], row['primary_label'], row['filename']), axis=1)\n",
    "filtered_pd = filtered_pd.assign(filename=full_path)\n",
    "\n",
    "\n",
    "filtered_pd.head(10)\n",
    "\n",
    "# Define YAMNet model\n",
    "yamnet_model_handle = \"https://tfhub.dev/google/yamnet/1\"\n",
    "yamnet_model = hub.load(yamnet_model_handle)\n",
    "\n",
    "# Extract embeddings\n",
    "def extract_embedding(wav_data, label):\n",
    "    scores, embeddings, spectrogram = yamnet_model(wav_data)\n",
    "    num_embeddings = tf.shape(embeddings)[0]\n",
    "    return (embeddings, tf.repeat(label, num_embeddings))\n",
    "\n",
    "def load_wav_16k_mono(filename):\n",
    "    try:\n",
    "        file_contents = tf.io.read_file(filename)\n",
    "        wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "        wav = tf.squeeze(wav, axis=-1)\n",
    "        sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "        wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "        return wav\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filename}: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def load_wav_for_map(filename, label):\n",
    "    return load_wav_16k_mono(filename), label\n",
    "\n",
    "# Create TensorFlow Dataset for training and testing\n",
    "def create_dataset(filenames, targets, split):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, targets))\n",
    "    dataset = dataset.map(lambda x, y: load_wav_for_map(x, y)).map(extract_embedding).unbatch()\n",
    "    dataset = dataset.cache()\n",
    "\n",
    "    if split == 'train':\n",
    "        dataset = dataset.shuffle(1000)\n",
    "    \n",
    "    dataset = dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_filenames = filtered_pd[filtered_pd['split'] == 'train']['filename']\n",
    "\n",
    "train_ds = create_dataset(filtered_pd[filtered_pd['split'] == 'train']['filename'],\n",
    "                          filtered_pd[filtered_pd['split'] == 'train']['target'], 'train')\n",
    "\n",
    "test_ds = create_dataset(filtered_pd[filtered_pd['split'] == 'test']['filename'],\n",
    "                         filtered_pd[filtered_pd['split'] == 'test']['target'], 'test')\n",
    "\n",
    "# Remove label column from the datasets\n",
    "remove_label_column = lambda embedding, label: (embedding, label)\n",
    "\n",
    "train_ds = train_ds.map(remove_label_column)\n",
    "test_ds = test_ds.map(remove_label_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "15/15 [==============================] - 8s 147ms/step - loss: 2.2884 - accuracy: 0.2208\n",
      "Epoch 2/30\n",
      "15/15 [==============================] - 2s 136ms/step - loss: 1.9518 - accuracy: 0.3167\n",
      "Epoch 3/30\n",
      "15/15 [==============================] - 2s 144ms/step - loss: 1.5955 - accuracy: 0.4167\n",
      "Epoch 4/30\n",
      "15/15 [==============================] - 2s 161ms/step - loss: 1.3463 - accuracy: 0.5188\n",
      "Epoch 5/30\n",
      "15/15 [==============================] - 2s 143ms/step - loss: 1.3175 - accuracy: 0.5479\n",
      "Epoch 6/30\n",
      "15/15 [==============================] - 2s 131ms/step - loss: 1.0745 - accuracy: 0.6708\n",
      "Epoch 7/30\n",
      "15/15 [==============================] - 2s 150ms/step - loss: 1.0067 - accuracy: 0.6792\n",
      "Epoch 8/30\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 1.1275 - accuracy: 0.7021\n",
      "Epoch 9/30\n",
      "15/15 [==============================] - 3s 178ms/step - loss: 0.9685 - accuracy: 0.7417\n",
      "Epoch 10/30\n",
      "15/15 [==============================] - 2s 129ms/step - loss: 1.3348 - accuracy: 0.6375\n",
      "Epoch 11/30\n",
      "15/15 [==============================] - 2s 153ms/step - loss: 1.2131 - accuracy: 0.6604\n",
      "Epoch 12/30\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0551 - accuracy: 0.6792\n",
      "Epoch 13/30\n",
      "15/15 [==============================] - 2s 127ms/step - loss: 0.8165 - accuracy: 0.7292\n",
      "Epoch 14/30\n",
      "15/15 [==============================] - 2s 162ms/step - loss: 0.6150 - accuracy: 0.8271\n",
      "Epoch 15/30\n",
      "15/15 [==============================] - 1s 93ms/step - loss: 0.6740 - accuracy: 0.8396\n",
      "Epoch 16/30\n",
      "15/15 [==============================] - 2s 139ms/step - loss: 0.7465 - accuracy: 0.7958\n",
      "Epoch 17/30\n",
      "15/15 [==============================] - 2s 131ms/step - loss: 1.1610 - accuracy: 0.7792\n",
      "Epoch 18/30\n",
      "15/15 [==============================] - 2s 131ms/step - loss: 0.9433 - accuracy: 0.7875\n",
      "Epoch 19/30\n",
      "15/15 [==============================] - 2s 164ms/step - loss: 1.1624 - accuracy: 0.8062\n",
      "Epoch 20/30\n",
      "15/15 [==============================] - 3s 180ms/step - loss: 0.7606 - accuracy: 0.8271\n",
      "Epoch 21/30\n",
      "15/15 [==============================] - 2s 144ms/step - loss: 1.3185 - accuracy: 0.7583\n",
      "Epoch 22/30\n",
      "15/15 [==============================] - 2s 149ms/step - loss: 1.1532 - accuracy: 0.7708\n",
      "Epoch 23/30\n",
      "15/15 [==============================] - 2s 164ms/step - loss: 1.0257 - accuracy: 0.7250\n",
      "Epoch 24/30\n",
      "15/15 [==============================] - 2s 130ms/step - loss: 0.6096 - accuracy: 0.8521\n",
      "Epoch 25/30\n",
      "15/15 [==============================] - 2s 136ms/step - loss: 0.4772 - accuracy: 0.8896\n",
      "Epoch 26/30\n",
      "15/15 [==============================] - 4s 298ms/step - loss: 0.3508 - accuracy: 0.9292\n",
      "Epoch 27/30\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2292 - accuracy: 0.9646\n",
      "Epoch 28/30\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 0.5387 - accuracy: 0.9146\n",
      "Epoch 29/30\n",
      "15/15 [==============================] - 2s 131ms/step - loss: 1.3831 - accuracy: 0.7229\n",
      "Epoch 30/30\n",
      "15/15 [==============================] - 2s 146ms/step - loss: 1.4173 - accuracy: 0.6583\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 2.6563 - accuracy: 0.3695\n",
      "Loss:  2.6563286781311035\n",
      "Accuracy:  0.36948975920677185\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to create and compile the model\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_model(input_shape, num_classes):\n",
    "    input_layer = layers.Input(shape=input_shape, dtype=tf.float32, name='input_embedding')\n",
    "    \n",
    "    \n",
    "    x = layers.Dense(512, activation='relu')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)  \n",
    "    x = layers.Dense(256, activation='relu')(x)  \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    output_layer = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
    "    return model\n",
    "\n",
    "\n",
    "# Function to compile the model with specified optimizer and learning rate\n",
    "def compile_model(model, learning_rate):\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, train_dataset, epochs, steps_per_epoch):\n",
    "    history = model.fit(train_dataset,\n",
    "                        epochs=epochs,\n",
    "                        steps_per_epoch=steps_per_epoch)\n",
    "    return history\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_dataset):\n",
    "    loss, accuracy = model.evaluate(test_dataset)\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "model = create_model(input_shape=(1024,), num_classes=len(my_classes))\n",
    "model = compile_model(model, learning_rate=0.001)\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "total_samples = len(train_filenames)\n",
    "steps_per_epoch = total_samples // batch_size\n",
    "\n",
    "\n",
    "history = model.fit(train_ds, epochs=30, steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "\n",
    "loss, accuracy = evaluate_model(model, test_ds)\n",
    "\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"b_bird_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
